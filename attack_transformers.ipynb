{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from attack_utils import get_grad, get_approximate_scores\n",
    "import resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grads for Bert Raw Embeddings vs Grads for embeddings from BERT LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-setup\n",
    "original_param_name_to_requires_grad_dict = {}\n",
    "for param_name, param in model.named_parameters():\n",
    "    original_param_name_to_requires_grad_dict[param_name] = param.requires_grad\n",
    "    param.requires_grad = True\n",
    "orig_mode = model.training\n",
    "model = model.train(mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = []\n",
    "\n",
    "layer = model.bert\n",
    "def hook_layers(module, grad_in, grad_out):\n",
    "    grads = grad_out[0]\n",
    "    print('Grad out:', grad_out)\n",
    "    gradients.append(grads)\n",
    "\n",
    "hooks = []\n",
    "hooks.append(layer.register_full_backward_hook(hook_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "output = model(**X, labels=y)\n",
    "for p in model.parameters():\n",
    "    p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# restore the original requires_grad values of the parameters\n",
    "for param_name, param in model.named_parameters():\n",
    "    param.requires_grad = original_param_name_to_requires_grad_dict[param_name]\n",
    "model.train(mode=orig_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack dataset\n",
    "from allennlp_extra.data.dataset_readers import load_csv\n",
    "\n",
    "test_json_path = '../data/ag_news/data/test.json' # 7,600\n",
    "data, labels = load_csv(test_json_path)\n",
    "\n",
    "\n",
    "for idx in range(labels.size(0)):\n",
    "    # construct X, y \n",
    "    text = data[idx]\n",
    "    X = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    X = {k: v.squeeze().to(device) for k, v in X.items()}\n",
    "    X['input_ids'].requires_grad=True\n",
    "    label = labels[idx]\n",
    "    label.sub_(1)\n",
    "    y = torch.LongTensor(label)\n",
    "    \n",
    "    # get grad\n",
    "    model.eval()\n",
    "    output = model(**X, labels=y)\n",
    "    loss = output['loss']\n",
    "    output.backward()\n",
    "    grads = X['input_ids'].grad.cpu().data.numpy()[0, ]\n",
    "\n",
    "    #\n",
    "    new_data = X['input_ids'].data.numpy()\n",
    "    x, y = np.nonzero(new_data) # x : index of char ; y : index of the word\n",
    "    values = grads[:, y] - grads[x, y]\n",
    "    values[x, np.arange(y.shape[0])] = -np.inf\n",
    "    # num_corrupt = int(round(y.shape[0] * self.per_corrupt / 100.))\n",
    "    # candidates = sorted(zip(values.max(axis=0), y, values.argmax(axis=0)), reverse=True)\n",
    "    # return candidates, new_data, num_corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import jiwer\n",
    "\n",
    "import resource\n",
    "import pickle\n",
    "from resource import get_sentiment_lexicon\n",
    "\n",
    "from textflint.common.settings import MODIFIED_MASK\n",
    "from textflint.common.utils.word_op import swap\n",
    "from textflint.generation.transformation import WordSubstitute\n",
    "from textflint.generation.transformation.UT import Keyboard, Typos\n",
    "from textflint.input.component.sample import UTSample\n",
    "from utils import visualize_text_diff, Accent, TypoSwap, AddVowel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from allennlp.training.metrics import CategoricalAccuracy, Average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Corruption Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(dataset_name, model_name='bert-base-uncased-SST-2', acc=True, print_fail_example=False):\n",
    "    with open(f'outputs_local/{dataset_name}_noisy.pickle', 'rb') as file:\n",
    "        noisy_data = pickle.load(file)\n",
    "    \n",
    "    with open(f'outputs/{dataset_name}_{model_name}.pickle', 'rb') as file:\n",
    "        examples = pickle.load(file)\n",
    "\n",
    "    df = pd.DataFrame.from_dict( examples )\n",
    "    \n",
    "    noiser_names = [k[2:] for k in noisy_data[0][1].keys() if k.startswith('x_')]\n",
    "    if acc:\n",
    "        if dataset_name != \"sentiment-lexicon\":\n",
    "            df['conf'] = df.apply(lambda example:  torch.nn.functional.softmax(example.logit, dim=0).tolist()[example.label], axis=1)\n",
    "            df['conf_clean'] = df.apply(lambda example: torch.nn.functional.softmax(example.logit_clean, dim=0).tolist()[example.label], axis=1)\n",
    "            df['pred'] = df.logit.map(lambda logit: torch.argmax(logit, dim=0).item())\n",
    "            df['pred_clean'] =df.logit_clean.map(lambda logit: torch.argmax(logit, dim=0).item())\n",
    "            df['correct'] = df.pred == df.label\n",
    "            df['correct_clean'] = df.pred_clean == df.label\n",
    "            print('Clean Accuracy:', df['correct_clean'].mean())\n",
    "        wcs1_round_dist = {}\n",
    "        for score in sorted(df['countM_round'].unique()):\n",
    "            examples = df[(df['countM_round'] == score)] # [df['wcr1'] >= 0.5]\n",
    "\n",
    "            print(f'Metric for {score}')\n",
    "            print( 'sim: ', examples['cos_sim'].mean())\n",
    "\n",
    "            if dataset_name != \"sentiment-lexicon\":\n",
    "                print( 'acc:', examples.correct.mean())\n",
    "                print( 'conf:', df.conf.mean())\n",
    "\n",
    "            wcs1_round_dist[score] =  len(examples)\n",
    "\n",
    "        print('Score Distribution: ', wcs1_round_dist)\n",
    "        \n",
    "        for noise_type in noiser_names:\n",
    "            if dataset_name != \"sentiment-lexicon\":\n",
    "                print(f'acc for {noise_type}: ', df[df.noise_type==noise_type].correct.mean())\n",
    "            print(f'avg sim for {noise_type}: ', df[df.noise_type==noise_type].cos_sim.mean())\n",
    "        return df, wcs1_round_dist\n",
    "\n",
    "    else: # evaluating word corruption\n",
    "        for noise_type in noiser_names:\n",
    "            print(f'avg countM for {noise_type}: ', df[df.noise_type==noise_type]['countM'].mean())\n",
    "            print(f'avg countO for {noise_type}: ', df[df.noise_type==noise_type]['countO'].mean())\n",
    "            \n",
    "            print(f'avg wcr1 for {noise_type}: ', df[df.noise_type==noise_type]['wcr1'].mean())\n",
    "            print(f'avg wcr2 for {noise_type}: ', df[df.noise_type==noise_type]['wcr2'].mean())\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = evaluate(dataset_name = 'sst2', model_name='bert-base-uncased-SST-2', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.7090413430611124\n",
    "# avg wcs2 for keyboard:  2.5738500562223776\n",
    "# avg_wcs1 for typoswap:  2.799669421127409\n",
    "# avg wcs2 for typoswap:  2.667305596959634\n",
    "# avg_wcs1 for addvowel:  2.7429717667773654\n",
    "# avg wcs2 for addvowel:  2.6156633804903966\n",
    "# avg_wcs1 for deletevowel:  2.213905232603751\n",
    "# avg wcs2 for deletevowel:  2.103615229727261\n",
    "# avg wcr for keyboard:  0.9609511097745588\n",
    "# avg wcr for typoswap:  0.9267708705606847\n",
    "# avg wcr for addvowel:  0.9611525551400627\n",
    "# avg wcr for deletevowel:  0.961481263565284\n",
    "\n",
    "# {2: 3127, 3: 3631, 4: 411, 1: 39, 5: 4, 6: 1}\n",
    "# {2: 3575, 3: 3034, 1: 192, 4: 370, 0: 32, 5: 5, -1: 1, -4: 1, -2: 3}\n",
    "\n",
    "\n",
    "# _ = evaluate(dataset_name = 'sst2', model_name='roberta-base-SST-2', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.44691539621523\n",
    "# avg wcs2 for keyboard:  1.9758531419157424\n",
    "# avg_wcs1 for typoswap:  2.5041866059987967\n",
    "# avg wcs2 for typoswap:  2.061454764955588\n",
    "# avg_wcs1 for accent:  2.810084072069245\n",
    "# avg wcs2 for accent:  2.3118884181899\n",
    "# avg_wcs1 for addvowel:  2.0265010067728375\n",
    "# avg wcs2 for addvowel:  1.424918717258092\n",
    "# avg_wcs1 for deletevowel:  1.7747685729975682\n",
    "# avg wcs2 for deletevowel:  1.305347009753927\n",
    "# avg wcr for keyboard:  0.859715016459938\n",
    "# avg wcr for typoswap:  0.8340726430910395\n",
    "# avg wcr for accent:  0.8672375126754583\n",
    "# avg wcr for addvowel:  0.7967297207186005\n",
    "# avg wcr for deletevowel:  0.8195677051099899\n",
    "# {2: 5587, 3: 3007, 1: 303, 4: 136, 5: 1}\n",
    "# {1: 2065, 2: 5093, 3: 1335, 0: 429, -1: 20, -2: 5, 4: 83, -4: 2, 5: 1, -3: 1}\n",
    "\n",
    "# _ = evaluate(dataset_name = 'sst2', model_name='albert-base-v2-SST-2', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.8127842716804814\n",
    "# avg wcs2 for keyboard:  2.6546148113281567\n",
    "# avg_wcs1 for typoswap:  2.9184821265134264\n",
    "# avg wcs2 for typoswap:  2.7681238722836747\n",
    "# avg_wcs1 for addvowel:  2.822527086983431\n",
    "# avg wcs2 for addvowel:  2.662344952625021\n",
    "# avg_wcs1 for deletevowel:  2.4301260427290066\n",
    "# avg wcs2 for deletevowel:  2.2826811101522786\n",
    "# avg wcr for keyboard:  0.9554387934623491\n",
    "# avg wcr for typoswap:  0.923595232284141\n",
    "# avg wcr for addvowel:  0.9553206128384613\n",
    "# avg wcr for deletevowel:  0.9541948359672145\n",
    "# {2: 2420, 3: 4067, 1: 31, 4: 683, 5: 10, 6: 2}\n",
    "# {2: 2944, 3: 3438, 1: 205, 0: 37, 4: 570, -1: 5, 5: 10, 6: 2, -2: 1, -4: 1}\n",
    "\n",
    "\n",
    "# _ = evaluate(dataset_name = 'ag_news', model_name='bert-base-uncased-ag-news', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.8104921679198\n",
    "# avg wcs2 for keyboard:  2.6720643796992474\n",
    "# avg_wcs1 for typoswap:  2.9162065058479416\n",
    "# avg wcs2 for typoswap:  2.7908166771094387\n",
    "# avg_wcs1 for addvowel:  2.879942669172933\n",
    "# avg wcs2 for addvowel:  2.750829939431903\n",
    "# avg_wcs1 for deletevowel:  2.3374996867168005\n",
    "# avg wcs2 for deletevowel:  2.222669851712619\n",
    "# avg wcr for keyboard:  0.9660402143327853\n",
    "# avg wcr for typoswap:  0.9731955724422094\n",
    "# avg wcr for addvowel:  0.9724244452677625\n",
    "# avg wcr for deletevowel:  0.972658962886332\n",
    "# {2: 8999, 3: 20819, 4: 579, 1: 2, 5: 1}\n",
    "# {2: 11177, 3: 18173, 1: 213, 4: 494, 0: 145, -1: 124, -2: 63, -3: 10, 5: 1}\n",
    "\n",
    "# _ = evaluate(dataset_name = 'ag_news', model_name='roberta-base-ag-news', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.583346282372606\n",
    "# avg wcs2 for keyboard:  2.1602525584795385\n",
    "# avg_wcs1 for typoswap:  2.720036810776932\n",
    "# avg wcs2 for typoswap:  2.3375206244778726\n",
    "# avg_wcs1 for accent:  3.010172096908925\n",
    "# avg wcs2 for accent:  2.5774957706766974\n",
    "# avg_wcs1 for addvowel:  2.2825703842940785\n",
    "# avg wcs2 for addvowel:  1.7649792188805378\n",
    "# avg_wcs1 for deletevowel:  2.0007397660818675\n",
    "# avg wcs2 for deletevowel:  1.584029344193816\n",
    "# avg wcr for keyboard:  0.8790120615485868\n",
    "# avg wcr for typoswap:  0.8943126792559514\n",
    "# avg wcr for accent:  0.8918039216605981\n",
    "# avg wcr for addvowel:  0.8397485190680145\n",
    "# avg wcr for deletevowel:  0.8567709565423209\n",
    "# {2: 19317, 3: 18247, 1: 87, 4: 349}\n",
    "# {2: 23706, 3: 8915, 1: 4719, 0: 312, -1: 161, 4: 119, -2: 61, -3: 7}\n",
    "\n",
    "\n",
    "# _ = evaluate(dataset_name = 'ag_news', model_name='albert-base-v2-ag-news', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.900427944862154\n",
    "# avg wcs2 for keyboard:  2.734204312865504\n",
    "# avg_wcs1 for typoswap:  3.041368159983297\n",
    "# avg wcs2 for typoswap:  2.888366802422725\n",
    "# avg_wcs1 for addvowel:  2.947591426482873\n",
    "# avg wcs2 for addvowel:  2.784188544277361\n",
    "# avg_wcs1 for deletevowel:  2.5583729636591497\n",
    "# avg wcs2 for deletevowel:  2.4078908208020113\n",
    "# avg wcr for keyboard:  0.9595087553795595\n",
    "# avg wcr for typoswap:  0.9677527147433647\n",
    "# avg wcr for addvowel:  0.96449697216978\n",
    "# avg wcr for deletevowel:  0.964713461537189\n",
    "# {2: 5857, 3: 23072, 4: 1469, 5: 1, 1: 1}\n",
    "# {2: 8720, 3: 19908, 1: 195, 0: 132, 4: 1207, -1: 71, -2: 137, -3: 24, 5: 1, -4: 5}\n",
    "\n",
    "# _ = evaluate(dataset_name = 'sentiment-lexicon', model_name='bert-base-uncased-SST-2', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.6525\n",
    "# avg wcs2 for keyboard:  1.91\n",
    "# avg_wcs1 for typoswap:  2.6775\n",
    "# avg wcs2 for typoswap:  2.1225\n",
    "# avg_wcs1 for addvowel:  2.775\n",
    "# avg wcs2 for addvowel:  2.095\n",
    "# avg_wcs1 for deletevowel:  2.2775\n",
    "# avg wcs2 for deletevowel:  1.65\n",
    "# {1: 90, 3: 260, 5: 25, 4: 131, 2: 268, 6: 3}\n",
    "# {-1: 53, 3: 194, 5: 25, 4: 118, 2: 178, 0: 69, 1: 110, -3: 3, -2: 24, 6: 3}\n",
    "\n",
    "# _ = evaluate(dataset_name = 'sentiment-lexicon', model_name='roberta-base-SST-2', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.39\n",
    "# avg wcs2 for keyboard:  1.2\n",
    "# avg_wcs1 for typoswap:  2.26\n",
    "# avg wcs2 for typoswap:  1.41\n",
    "# avg_wcs1 for accent:  2.6225\n",
    "# avg wcs2 for accent:  1.4275\n",
    "# avg_wcs1 for addvowel:  1.78\n",
    "# avg wcs2 for addvowel:  0.39\n",
    "# avg_wcs1 for deletevowel:  1.6825\n",
    "# avg wcs2 for deletevowel:  0.64\n",
    "# {2: 465, 1: 198, 3: 257, 4: 57, 5: 4}\n",
    "# {0: 198, -1: 107, 1: 274, 2: 216, 3: 113, 4: 35, 5: 2, -2: 34, -3: 1, -4: 1}\n",
    "\n",
    "\n",
    "# _ = evaluate(dataset_name = 'sentiment-lexicon', model_name='albert-base-v2-SST-2', acc=False)\n",
    "# avg_wcs1 for keyboard:  2.8\n",
    "# avg wcs2 for keyboard:  2.1025\n",
    "# avg_wcs1 for typoswap:  2.725\n",
    "# avg wcs2 for typoswap:  2.095\n",
    "# avg_wcs1 for addvowel:  2.8075\n",
    "# avg wcs2 for addvowel:  2.0075\n",
    "# avg_wcs1 for deletevowel:  2.4075\n",
    "# avg wcs2 for deletevowel:  1.6425\n",
    "# {2: 264, 5: 39, 3: 238, 4: 148, 1: 82, 0: 1, 6: 5}\n",
    "# {1: 111, 5: 39, 3: 175, 4: 123, 2: 173, 0: 78, -1: 47, -2: 16, -3: 13, 6: 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transform']\n",
      "['transform', '##er']\n",
      "['transform']\n",
      "['trans', 'former']\n",
      "['▁transform']\n",
      "['▁transform', 'er']\n"
     ]
    }
   ],
   "source": [
    "print(resource.hf_tokenizers['bert'].tokenize('transform'))\n",
    "# print(resource.hf_tokenizers['bert'].tokenize('transformerify'))\n",
    "print(resource.hf_tokenizers['bert'].tokenize('transformer'))\n",
    "\n",
    "print(resource.hf_tokenizers['roberta'].tokenize('transform'))\n",
    "# print(resource.hf_tokenizers['roberta'].tokenize('transformerify'))\n",
    "print(resource.hf_tokenizers['roberta'].tokenize('transformer'))\n",
    "\n",
    "print(resource.hf_tokenizers['albert'].tokenize('transform'))\n",
    "# print(resource.hf_tokenizers['albert'].tokenize('transformerify'))\n",
    "print(resource.hf_tokenizers['albert'].tokenize('transformer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating PLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy: 0.9511842105263157\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'countM_round'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/allennlp-dev/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/allennlp-dev/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/allennlp-dev/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'countM_round'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_905/1939114702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ag_news\"\u001b[0m\u001b[0;31m#'sentiment-lexicon'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bert-base-uncased-ag-news'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_905/4049676671.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset_name, model_name, acc, print_fail_example)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Clean Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mwcs1_round_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countM_round'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countM_round'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# [df['wcr1'] >= 0.5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/allennlp-dev/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/allennlp-dev/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'countM_round'"
     ]
    }
   ],
   "source": [
    "dataset_name = \"ag_news\"#'sentiment-lexicon'\n",
    "model_name = 'bert-base-uncased-ag-news'\n",
    "df = evaluate(dataset_name = dataset_name, model_name=model_name, acc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([-0.2413], device='cuda:0'), ['efEectiveness']),\n",
       " (tensor([-0.2331], device='cuda:0'), ['effeectiveness']),\n",
       " (tensor([0.8876], device='cuda:0'), ['effctiveness']),\n",
       " (tensor([0.7405], device='cuda:0'), ['un#estricted']),\n",
       " (tensor([-0.2110], device='cuda:0'), ['iBteresting']),\n",
       " (tensor([-0.1207], device='cuda:0'), ['s Tbstantive']),\n",
       " (tensor([-0.1109], device='cuda:0'), ['sbustantive']),\n",
       " (tensor([-0.1111], device='cuda:0'), ['sbstantive']),\n",
       " (tensor([-0.0884], device='cuda:0'), ['spuerior']),\n",
       " (tensor([-0.2264], device='cuda:0'), ['influFntial']),\n",
       " (tensor([-0.1723], device='cuda:0'), ['(ntimate']),\n",
       " (tensor([-0.2089], device='cuda:0'), ['stisfied']),\n",
       " (tensor([0.1920], device='cuda:0'), ['extrao%dinary']),\n",
       " (tensor([0.4382], device='cuda:0'), ['extraordniary']),\n",
       " (tensor([-0.2509], device='cuda:0'), ['eneergetic']),\n",
       " (tensor([-0.0900], device='cuda:0'), ['sIccessful']),\n",
       " (tensor([-0.1952], device='cuda:0'), ['suuccessful']),\n",
       " (tensor([-0.1451], device='cuda:0'), ['dviersified']),\n",
       " (tensor([-0.2066], device='cuda:0'), ['pheenomenal']),\n",
       " (tensor([0.0120], device='cuda:0'), ['inexpeMsive']),\n",
       " (tensor([-0.1457], device='cuda:0'), ['ineexpensive']),\n",
       " (tensor([0.9817], device='cuda:0'), ['uneconojical']),\n",
       " (tensor([0.0650], device='cuda:0'), ['ut$erly']),\n",
       " (tensor([-0.0066], device='cuda:0'), ['uttrely']),\n",
       " (tensor([0.8432], device='cuda:0'), ['indOstinguishable']),\n",
       " (tensor([0.9877], device='cuda:0'), ['anti', '-', 'proliferatoin']),\n",
       " (tensor([0.9540], device='cuda:0'), ['illeegitimate']),\n",
       " (tensor([0.7291], device='cuda:0'), ['embaarrassment']),\n",
       " (tensor([0.8780], device='cuda:0'), ['embrrassment']),\n",
       " (tensor([0.9390], device='cuda:0'), ['mysteri9us']),\n",
       " (tensor([0.7188], device='cuda:0'), ['oppreessive']),\n",
       " (tensor([0.8529], device='cuda:0'), ['opprssive']),\n",
       " (tensor([0.9852], device='cuda:0'), ['oveersimplify']),\n",
       " (tensor([0.9237], device='cuda:0'), ['ovrsimplify']),\n",
       " (tensor([0.6245], device='cuda:0'), ['e%ror']),\n",
       " (tensor([0.9671], device='cuda:0'), ['unspeciCied']),\n",
       " (tensor([0.9572], device='cuda:0'), ['unspecifeid']),\n",
       " (tensor([0.9517], device='cuda:0'), ['unspeecified']),\n",
       " (tensor([0.9578], device='cuda:0'), ['dsperate'])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluator = evaluate(dataset_name = 'sentiment-lexicon', model_name='bert-base-uncased-SST-2')\n",
    "# {3: 256, 5: 25, 4: 131, 2: 212, 6: 3, 1: 1}\n",
    "# 1 1\n",
    "# (-0.1488560140132904, 0.0, -1.5045084953308105)\n",
    "# 2 212\n",
    "# (0.19941534588113427, 0.35, -0.6234171338379383)\n",
    "# 3 256\n",
    "# (0.08219806593609974, 0.33, -0.7116527155879885)\n",
    "# 4 131\n",
    "# (0.145205411426723, 0.37, -0.22009293557144702)\n",
    "# 5 25\n",
    "# (0.27900213867425916, 0.56, 0.421643493771553)\n",
    "# 6 3\n",
    "# (0.46120982865492505, 0.6666666666666666, 1.1079510400692623)\n",
    "\n",
    "# evaluator = evaluate(dataset_name = 'sentiment-lexicon', model_name='roberta-base-SST-2', )\n",
    "# {3: 254, 2: 322, 4: 57, 5: 4, 1: 5}\n",
    "# 1 5\n",
    "# (0.6891950249671936, 0.4, -0.1261606216430664)\n",
    "# 2 322\n",
    "# (0.6090222394093872, 0.55, -0.10270595621317626)\n",
    "# 3 254\n",
    "# (0.6933429863117635, 0.54, -0.1900323366187513)\n",
    "# 4 57\n",
    "# (0.6810957195988873, 0.5263157894736842, 0.25944323654760393)\n",
    "# 5 4\n",
    "# (0.7189953178167343, 0.25, -0.9385237395763397)\n",
    "\n",
    "# evaluator = evaluate(dataset_name = 'sentiment-lexicon', model_name='albert-base-v2-SST-2',)\n",
    "# {2: 194, 5: 39, 3: 233, 4: 148, 1: 4, 6: 5}\n",
    "# 1 4\n",
    "# (0.582113103941083, 1.0, 1.3808440417051315)\n",
    "# 2 194\n",
    "# (0.32992080080788583, 0.42, -0.1585123308375478)\n",
    "# 3 233\n",
    "# (0.17168018369469792, 0.47, -0.09391461444087326)\n",
    "# 4 148\n",
    "# (0.194426726475358, 0.51, 0.04141160725615919)\n",
    "# 5 39\n",
    "# (0.3544340170203493, 0.5384615384615384, 0.12848461684412682)\n",
    "# 6 5\n",
    "# (0.8808889627456665, 0.8, 0.6727136909961701)\n",
    "\n",
    "evaluator.examples_by_wbr1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-965b290e85bcd05f\n",
      "Reusing dataset csv (/home/xinzhel/.cache/huggingface/datasets/csv/default-965b290e85bcd05f/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
      "Loading cached shuffled indices for dataset at /home/xinzhel/.cache/huggingface/datasets/csv/default-965b290e85bcd05f/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-e45c4da6d4c31008.arrow\n",
      "Loading cached shuffled indices for dataset at /home/xinzhel/.cache/huggingface/datasets/csv/default-965b290e85bcd05f/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-e5b1c51a7a469a59.arrow\n",
      "Loading cached shuffled indices for dataset at /home/xinzhel/.cache/huggingface/datasets/csv/default-965b290e85bcd05f/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-f9c8f199bb22a336.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typoswap  has no change.\n",
      "['...', 'too', 'gory', 'to', 'be', 'a', 'comedy', 'and', 'too', 'silly', 'to', 'be', 'an', 'effective', 'horror', 'film', '.']\n",
      "['...', 'too', 'gory', 'to', 'be', 'a', 'comedy', 'and', 'too', 'silly', 'to', 'be', 'an', 'effective', 'horror', 'film', '.']\n",
      "typoswap  has no change.\n",
      "['Sorry', ',', 'Charlie']\n",
      "['Sorry', ',', 'Charlie']\n",
      "typoswap  has no change.\n",
      "['But', 'he', 'somehow', 'pulls', 'it', 'off', '.']\n",
      "['But', 'he', 'somehow', 'pulls', 'it', 'off', '.']\n",
      "typoswap  has no change.\n",
      "['A', 'very', 'funny', 'movie', '.']\n",
      "['A', 'very', 'funny', 'movie', '.']\n",
      "typoswap  has no change.\n",
      "['A', 'taut', ',', 'intelligent', 'psychological', 'drama', '.']\n",
      "['A', 'taut', ',', 'intelligent', 'psychological', 'drama', '.']\n",
      "typoswap  has no change.\n",
      "['Feels', 'less', 'like', 'it', \"'s\", 'about', 'teenagers', ',', 'than', 'it', 'was', 'written', 'by', 'teenagers', '.']\n",
      "['Feels', 'less', 'like', 'it', \"'s\", 'about', 'teenagers', ',', 'than', 'it', 'was', 'written', 'by', 'teenagers', '.']\n",
      "typoswap  has no change.\n",
      "['The', 'film', 'is', 'really', 'not', 'so', 'much', 'bad', 'as', 'bland', '.']\n",
      "['The', 'film', 'is', 'really', 'not', 'so', 'much', 'bad', 'as', 'bland', '.']\n",
      "typoswap  has no change.\n",
      "['It', 'settles', 'for', 'being', 'merely', 'grim', '.']\n",
      "['It', 'settles', 'for', 'being', 'merely', 'grim', '.']\n",
      "typoswap  has no change.\n",
      "['Little', 'more', 'than', 'a', 'frothy', 'vanity', 'project', '.']\n",
      "['Little', 'more', 'than', 'a', 'frothy', 'vanity', 'project', '.']\n",
      "{2: 3121, 3: 3630, 4: 411, 1: 33, 5: 4, 6: 1}\n",
      "1 33\n",
      "(0.6539115838258471, 0.8484848484848485, 1.6901389792505088)\n",
      "2 3121\n",
      "(0.5441384263336658, 0.62, 0.9030922737717628)\n",
      "3 3630\n",
      "(0.5394114886177703, 0.65, 0.9499093507230282)\n",
      "4 411\n",
      "(0.47562134861946104, 0.61, 0.9493890537321568)\n",
      "5 4\n",
      "(0.33443448320031166, 0.5, 0.7998999059200287)\n",
      "6 1\n",
      "(0.9617360830307007, 1.0, 3.446354866027832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/xinzhel/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Loading cached shuffled indices for dataset at /home/xinzhel/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-7b90e6a0c0b97720.arrow\n",
      "Loading cached shuffled indices for dataset at /home/xinzhel/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8d3a6c97826ce3fc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 8989, 3: 20819, 4: 579, 1: 2, 5: 1}\n",
      "1 2\n",
      "(0.9028977155685425, 1.0, 6.144953966140747)\n",
      "2 8989\n",
      "(0.8604478907585144, 0.85, 6.138670318871736)\n",
      "3 20819\n",
      "(0.8237378129176796, 0.87, 5.814665046930313)\n",
      "4 579\n",
      "(0.8259232801571489, 0.86, 5.378732451349497)\n",
      "5 1\n",
      "(0.9731678366661072, 1.0, 7.07002592086792)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-ag-news were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 19299, 3: 18245, 1: 85, 4: 349}\n",
      "1 85\n",
      "(0.4312978788552915, 0.5411764705882353, 2.66027578492375)\n",
      "2 19299\n",
      "(0.4754411730426364, 0.69, 3.332404831973836)\n",
      "3 18245\n",
      "(0.42333426532219165, 0.59, 2.7375627148058266)\n",
      "4 349\n",
      "(0.5509571685642004, 0.64, 3.216657065525651)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Evaluator at 0x7faff9f99cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluator = evaluate(dataset_name = 'sst2', model_name='bert-base-uncased-SST-2', print_fail_example=True)\n",
    "# {2: 3121, 3: 3630, 4: 411, 1: 33, 5: 4, 6: 1}\n",
    "# 1 33\n",
    "# (0.6539115838258471, 0.8484848484848485, 1.6901389792505088)\n",
    "# 2 3121\n",
    "# (0.5441384263336658, 0.62, 0.9030922737717628)\n",
    "# 3 3630\n",
    "# (0.5394114886177703, 0.65, 0.9499093507230282)\n",
    "# 4 411\n",
    "# (0.47562134861946104, 0.61, 0.9493890537321568)\n",
    "# 5 4\n",
    "# (0.33443448320031166, 0.5, 0.7998999059200287)\n",
    "# 6 1\n",
    "# (0.9617360830307007, 1.0, 3.446354866027832)\n",
    "\n",
    "evaluator = evaluate(dataset_name = 'sst2', model_name='roberta-base-SST-2')\n",
    "\n",
    "evaluator = evaluate(dataset_name = 'sst2', model_name='albert-base-v2-SST-2')\n",
    "\n",
    "# evaluator = evaluate(dataset_name = 'ag_news', model_name='bert-base-uncased-ag-news', print_fail_example=True)\n",
    "# {2: 8989, 3: 20819, 4: 579, 1: 2, 5: 1}\n",
    "# 1 2\n",
    "# (0.9028977155685425, 1.0, 6.144953966140747)\n",
    "# 2 8989\n",
    "# (0.8604478907585144, 0.85, 6.138670318871736)\n",
    "# 3 20819\n",
    "# (0.8237378129176796, 0.87, 5.814665046930313)\n",
    "# 4 579\n",
    "# (0.8259232801571489, 0.86, 5.378732451349497)\n",
    "# 5 1\n",
    "# (0.9731678366661072, 1.0, 7.07002592086792)\n",
    "\n",
    "# evaluator = evaluate(dataset_name = 'ag_news', model_name='roberta-base-ag-news', print_fail_example=True)\n",
    "# {2: 19299, 3: 18245, 1: 85, 4: 349}\n",
    "# 1 85\n",
    "# (0.4312978788552915, 0.5411764705882353, 2.66027578492375)\n",
    "# 2 19299\n",
    "# (0.4754411730426364, 0.69, 3.332404831973836)\n",
    "# 3 18245\n",
    "# (0.42333426532219165, 0.59, 2.7375627148058266)\n",
    "# 4 349\n",
    "# (0.5509571685642004, 0.64, 3.216657065525651)\n",
    "\n",
    "evaluate(dataset_name = 'ag_news', model_name='textattack/albert-base-v2-ag-news', print_fail_example=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eff', 'Ã©', 'ct', 'iveness']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimum Functional Text\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "\n",
    "with open(f\"outputs/sentiment-lexicon_noisy.pickle\", 'rb') as f:\n",
    "    noisy_data = pickle.load(f)\n",
    "\n",
    "assert len(noisy_data) == 200\n",
    "pos_lexicon, neg_lexicon = noisy_data[:100], noisy_data[100:]\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos', pos_lexicon)\n",
    "editor.add_lexicon('neg', neg_lexicon)\n",
    "\n",
    "mft_pos_examples = editor.template('This is {pos}', labels = 1,)\n",
    "mft_neg_examples = editor.template('This is {neg}', labels = 0, )\n",
    "mft_data = mft_pos_examples.data\n",
    "mft_data.extend(mft_neg_examples.data)\n",
    "mft_labels = mft_pos_examples.labels\n",
    "mft_labels.extend(mft_neg_examples.labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 't', 'aaa', 'sty']\n",
      "['▁', 't', 'aaa', 'sty']\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "tokenizer = resource.hf_tokenizers['albert']\n",
    "plm = resource.hf_models['bert']\n",
    "data = resource.datasets['ag_news']\n",
    "ag_news = [\"\"\"Fears efféctiveness.\"\"\"]\n",
    "print(tokenizer.tokenize('taaasty'))\n",
    "print(tokenizer.tokenize('taaasty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the effectiveness of different noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "wordpiece_no_accent = AutoTokenizer.from_pretrained('bert-base-uncased', strip_accents=False) \n",
    "wordpiece_no_accent_res = textflint_transform(sample, wordpiece_no_accent, n_trans = 100,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpiece_no_accent_res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordpiece_no_accent_res['orig_tokens'])\n",
    "print(wordpiece_no_accent_res['accent_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word breaking of different noises\n",
    "wordpiece_bert = resource.hf_tokenizers['bert-base-uncased']\n",
    "bpe_roberta = resource.hf_tokenizers['roberta-base']\n",
    "pos_lexicon50, neg_lexicon50 = get_sentiment_lexicon(n=50)\n",
    "concat_text = ' '.join(neg_lexicon50 + pos_lexicon50)\n",
    "\n",
    "sample = UTSample({'x': concat_text})\n",
    "wordpiece_res = textflint_transform(sample, wordpiece_bert, n_trans = 100,)\n",
    "bpe_res = textflint_transform(sample, bpe_roberta, n_trans = 100, )\n",
    "# only length\n",
    "wordpiece_res = {key : value for key, value in wordpiece_res.items() if 'length' in key }\n",
    "bpe_res = {key : value for key, value in bpe_res.items() if 'length' in key }\n",
    "print(wordpiece_res)\n",
    "print(bpe_res)\n",
    "# wordpiece_diff = {'orig_length': 0, 'typos_length': 0, 'keyboard_length': 0, 'accent_length': 0}\n",
    "# bpe_diff = {'orig_length': 0, 'typos_length': 0, 'keyboard_length': 0, 'accent_length': 0}\n",
    "# for k, v in wordpiece_res:\n",
    "#     wordpiece_diff[k] += wordpiece_res[k]\n",
    "#     bpe_diff[k] += bpe_res[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_roberta.tokenize('tmorw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_orig, accuracy_orig = predict_batch(mft_data, labels)\n",
    "pred_keyboard, accuracy_keyboard = predict_batch(keyboard_examples, labels)\n",
    "pred_typos, accuracy_typos = predict_batch(typos_examples, labels)\n",
    "pred_accent, accuracy_accent = predict_batch(accent_examples, labels)\n",
    "print(accuracy_orig, accuracy_keyboard, accuracy_typos, accuracy_accent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axes = plt.subplots(nrows=2, ncols=2)\n",
    "titles = [\n",
    "    # we select different types of language models according to pretraining strategies (tasks)\n",
    "    # autoregressive (GPT2), auto-encoding (bert, xlnet, ), enc-dec (BART)\n",
    "    #  xlnet, bert, roberta\n",
    "    'textattack/bert-base-uncased-SST-2', \n",
    "    'textattack/distilbert-base-uncased-SST-2', \n",
    "    'textattack/albert-base-v2-SST-2',\n",
    "    'textattack/roberta-base-SST-2']\n",
    "for i, ax1 in enumerate(axes.flat):\n",
    "    wbr_density = globals()['wbr_density'+str(i+1)]\n",
    "    accuracy_dict = globals()['accuracy_dict'+str(i)]\n",
    "    ax1.bar(wbr_density.keys(), wbr_density.values(), color='g', alpha=0.4, label='WBR')\n",
    "    ax1.legend(loc='upper left',  frameon=True)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar(accuracy_dict.keys(), accuracy_dict.values(), color='r', alpha=0.5, label='Accuracy')\n",
    "    ax2.legend(loc='upper right', frameon=True)\n",
    "    ax1.set_title(titles[i])\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic words 不容易定位\n",
    "# TODO: Evaluation\n",
    "# 1. using datasets with different levels of context: SST2; Jigsaw, Yelp, AGnews context 更大 \n",
    "# TBD\n",
    "# 2. test with checklist DIR or confident on data with more context (e.g., more words reflecting class information)\n",
    "# Doing\n",
    "\n",
    "# TODO: not focusing on attack methods ; I try to focus on analysis\n",
    "# 2. compare different methods ; noise types combine gradient-based attack methods\n",
    "# Not important for this paper, which analyzes whether transformers can understand corrupted words; \n",
    "# BTW, the WIR words located are same\n",
    "# Mover GBWA in another paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"outputs/ag_news_noisy.pickle\", 'rb') as file:\n",
    "    ag_news_text = pickle.load(file)\n",
    "\n",
    "with open(\"outputs/sst2_noisy.pickle\", 'rb') as file:\n",
    "    sst2_text = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/sentiment-lexicon_noisy.pickle\", 'rb') as file:\n",
    "    lexicon_text = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard\n",
      "['effect', 'iveness']\n",
      "['ef', 'E', 'ect', 'iveness']\n",
      "typoswap\n",
      "['effect', 'iveness']\n",
      "['effect', 'v', 'ien', 'ess']\n",
      "accent\n",
      "['effect', 'iveness']\n",
      "['eff', 'Ã©', 'ct', 'iveness']\n",
      "addvowel\n",
      "['effect', 'iveness']\n",
      "['eff', 'e', 'ect', 'iveness']\n",
      "deletevowel\n",
      "['effect', 'iveness']\n",
      "['eff', 'ct', 'iveness']\n",
      "keyboard 3.0 2.0\n",
      "typoswap 3.0 2.0\n",
      "accent 3.0 2.0\n",
      "addvowel 3.0 2.0\n",
      "deletevowel 2.0 1.0\n",
      "{'x': ['effectiveness'], 'x_keyboard': ['efEectiveness'], 'x_typoswap': ['effectvieness'], 'x_accent': ['efféctiveness'], 'x_addvowel': ['effeectiveness'], 'x_deletevowel': ['effctiveness'], 'y': 1, 'wbr1_keyboard': 3.0, 'wbr2_keyboard': 2.0, 'wbr1_typoswap': 3.0, 'wbr2_typoswap': 2.0, 'wbr1_accent': 3.0, 'wbr2_accent': 2.0, 'wbr1_addvowel': 3.0, 'wbr2_addvowel': 2.0, 'wbr1_deletevowel': 2.0, 'wbr2_deletevowel': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# visualize_text_diff(' '.join(ag_news_text[0][1]['x']), ' '.join(ag_news_text[0][1]['x_accent']), color_method='html')\n",
    "model_bundle = resource.hf_model_bundles['roberta-base-SST-2']\n",
    "sst_evaluator = Evaluator(model_bundle, None)\n",
    "sst_evaluator.add_to_groups(lexicon_text[1][0], lexicon_text[1][1], print_wcs=True)\n",
    "print(lexicon_text[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x', 'x_keyboard', 'x_typoswap', 'x_accent', 'x_addvowel', 'x_deletevowel', 'y'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_text[0][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The story <font color = blue>may</font> not be new , <font color = blue>but</font> Australian <font color = blue>director</font> John Polson , making his American feature <font color = blue>debut</font> , <font color = blue>jazzes</font> it <font color = blue>up</font> <font color = blue>adroitly</font> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The story <font color = purple>mah</font> not be new , <font color = purple>Nut</font> Australian <font color = purple>dKrector</font> John Polson , making his American feature <font color = purple>devut</font> , <font color = purple>jazxes</font> it <font color = purple>kp</font> <font color = purple>Adroitly</font> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('The story <font color = blue>may</font> not be new , <font color = blue>but</font> Australian <font color = blue>director</font> John Polson , making his American feature <font color = blue>debut</font> , <font color = blue>jazzes</font> it <font color = blue>up</font> <font color = blue>adroitly</font> .',\n",
       " 'The story <font color = purple>mah</font> not be new , <font color = purple>Nut</font> Australian <font color = purple>dKrector</font> John Polson , making his American feature <font color = purple>devut</font> , <font color = purple>jazxes</font> it <font color = purple>kp</font> <font color = purple>Adroitly</font> .')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_text_diff(' '.join(sst2_text[0][1]['x']), ' '.join(sst2_text[0][1]['x_keyboard']), color_method='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(example, y):\n",
    "    result = dict()\n",
    "    device = next(model.parameters()).device\n",
    "    label = torch.LongTensor([y]).unsqueeze(0).to(device)\n",
    "    for k, v in example.items():\n",
    "        if k.startswith('x'):\n",
    "            X = tokenizer.encode_plus(v, return_tensors='pt')\n",
    "            X = {k: v.to(device) for k, v in X.items()}\n",
    "            model_output = model(**X, labels=label)\n",
    "            result['logits_'+k[2:]] = model_output['logits']\n",
    "    return result\n",
    "\n",
    "get_result(example, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_types import MFT, INV, DIR\n",
    "data = [[], []]\n",
    "test = INV(data=data)\n",
    "test.run(wrapped_pp)\n",
    "test.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b04ccbd0ebf9a379475fdf3211eaaf98859dac7e2af73e3f6f3303c032dc6f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('allennlp-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
